{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3fff78",
   "metadata": {},
   "source": [
    "# Parcial de Machine Learning — Modo Estudiante  \n",
    "**Instrucciones generales:**  \n",
    "- Entregar todo en un repositorio (GitHub/GitLab) con un `notebook` ejecutable (`.ipynb`) y un informe en `Markdown` (`REPORT.md`) o `PDF`.  \n",
    "- Cada proyecto debe contener: `README.md`, `data/` (o enlaces y scripts para descarga), `notebook.ipynb`, `requirements.txt` y `REPORT.md`.  \n",
    "- Escribe el código con recomendaciones de reproducibilidad (semillas aleatorias, versión de librerías en `requirements.txt`).  \n",
    "- Esta tarea está pensada para estudiantes universitarios: explica cada paso, justifica decisiones y comenta el código.\n",
    "\n",
    "---\n",
    "\n",
    "## Proyecto A — REGRESIÓN  \n",
    "**Título:** Predicción del rendimiento energético de edificios (Heating Load)  \n",
    "**Dataset (Kaggle):** Energy Efficiency Data Set — https://www.kaggle.com/datasets/elikplim/energy-efficiency-data-set\n",
    "\n",
    "### Contexto y motivación (para el estudiante)\n",
    "Los consumos energéticos de calefacción y refrigeración dependen de características físicas del edificio (compactación, áreas de superficie, altura, ventanas, orientación). Este dataset proviene de simulaciones que relacionan variables físicas de edificios con su “Heating Load” y “Cooling Load”. El objetivo práctico es poder estimar la carga de calefacción de un diseño o prototipo para optimizar materiales y diseño pasivo.\n",
    "\n",
    "### Data definition (definición de columnas)\n",
    "- `Relative Compactness` — compacidad relativa del edificio (float).  \n",
    "- `Surface Area` — área superficial total (float).  \n",
    "- `Wall Area` — área total de paredes (float).  \n",
    "- `Roof Area` — área del techo (float).  \n",
    "- `Overall Height` — altura total del edificio (float).  \n",
    "- `Orientation` — orientación del edificio (1 a 4) (int / categórico ordinal).  \n",
    "- `Glazing Area` — proporción/área de ventanas (float).  \n",
    "- `Glazing Area Distribution` — distribución de ventanas (1 a 5) (int / categórico ordinal).  \n",
    "- `Heating Load` — carga de calefacción (target, float).  \n",
    "- `Cooling Load` — carga de enfriamiento (float, no usada como target principal en esta tarea).\n",
    "\n",
    "### Objetivo de la entrega\n",
    "Construir y comparar modelos de regresión que predigan `Heating Load` a partir de las demás variables, justificar las decisiones de modelado y presentar un análisis de sensibilidad (qué variables influyen más).\n",
    "\n",
    "### Entregables específicos\n",
    "1. `notebook_regresion.ipynb` con todo el desarrollo reproducible.  \n",
    "2. `REPORT.md` (máximo 3 páginas) con: resumen, metodología, resultados, conclusiones y limitaciones.  \n",
    "3. Código para descargar y preprocesar los datos automáticamente (`download_data.py` o celdas en el notebook).  \n",
    "4. `requirements.txt` con versiones de librerías.\n",
    "\n",
    "### Tareas paso a paso (modo estudiante — cada ítem corresponde a un bloque/celda o sección del informe)\n",
    "\n",
    "#### 1. Exploración inicial (EDA)\n",
    "- Cargar datos y mostrar primeras filas.  \n",
    "- Verificar tipos de datos y buscar valores faltantes o atípicos.  \n",
    "- Resumen estadístico (media, std, min, max) para cada variable.  \n",
    "- Visualizar distribuciones (histogramas) de las variables numéricas y del target.  \n",
    "- Matriz de correlación y mapa de calor; comentar correlaciones relevantes con `Heating Load`.\n",
    "\n",
    "#### 2. Preprocesamiento\n",
    "- Tratar valores faltantes (si existen) — explicar la estrategia (imputación media/mediana, o eliminación).  \n",
    "- Transformaciones: identificar si alguna variable necesita transformación (log, escala, rank).  \n",
    "- Codificación de variables ordinales (`Orientation`, `Glazing Area Distribution`) — justificar si se tratan como numéricas u one-hot.  \n",
    "- Escalamiento: aplicar `StandardScaler` o `MinMaxScaler` y explicar elección.\n",
    "\n",
    "#### 3. División de datos\n",
    "- Dividir en `train` (70-80%) y `test` (20-30%) con `random_state` fijo.  \n",
    "- (Opcional) reservar un `validation set` o usar `cross-validation` anidada para selección de hiperparámetros.\n",
    "\n",
    "#### 4. Línea base (baseline)\n",
    "- Implementar una regresión lineal simple (OLS) como baseline. Reportar MAE, RMSE y R² en test.  \n",
    "- Documentar por qué esto sirve como referencia.\n",
    "\n",
    "#### 5. Modelos a comparar\n",
    "Entrena y compara al menos **tres** de los siguientes (justifica elección):\n",
    "- Linear Regression / Ridge / Lasso (regularizados).  \n",
    "- Decision Tree Regressor.  \n",
    "- Random Forest Regressor.  \n",
    "- Gradient Boosting (XGBoost / LightGBM / CatBoost).  \n",
    "- SVR (cuando tenga sentido y dimensiones pequeñas).\n",
    "\n",
    "Para cada modelo:\n",
    "- Hacer búsqueda de hiperparámetros (GridSearchCV o RandomizedSearchCV) con `cv=5`.  \n",
    "- Evaluar en `test set` con métricas: MAE, RMSE, R².  \n",
    "- Mostrar aprendizaje (curvas de entrenamiento / validación) para al menos un modelo complejo.\n",
    "\n",
    "#### 6. Interpretabilidad y análisis de características\n",
    "- Reportar importancias de variables (feature importances o coeficientes).  \n",
    "- Usar SHAP o Permutation Importance como análisis complementario (si se dispone).  \n",
    "- Hacer un análisis de sensibilidad: ¿cómo cambia `Heating Load` cuando varía `Overall Height` o `Glazing Area` manteniendo otros factores constantes? (plot parcial dependence o gráficos sencillos).\n",
    "\n",
    "#### 7. Evaluación de robustez\n",
    "- Probar el modelo contra outliers (remover top 1% y evaluar cambios).  \n",
    "- Verificar estabilidad con distintas semillas aleatorias.\n",
    "\n",
    "#### 8. Conclusiones y recomendaciones\n",
    "- Resumir el mejor modelo y por qué.  \n",
    "- Recomendaciones de uso práctico (por ejemplo, si sirve para estimaciones preliminares de diseño).  \n",
    "- Limitaciones del dataset (simulado, rango de valores, posibles sesgos).\n",
    "\n",
    "### Criterio de evaluación sugerido (para el profesor)\n",
    "- EDA y justificación de decisiones: 20%  \n",
    "- Calidad del preprocesamiento: 15%  \n",
    "- Implementación y comparación de modelos: 30%  \n",
    "- Interpretabilidad y análisis: 20%  \n",
    "- Presentación y reproducibilidad (notebook limpio, `requirements.txt`, README): 15%\n",
    "\n",
    "### Pistas y recursos\n",
    "- Recomendado: usar `scikit-learn`, `pandas`, `matplotlib`, `seaborn`, `shap` (opcional).  \n",
    "- Mantener `random_state=42` en todas las divisiones para reproducibilidad.  \n",
    "- Si usa XGBoost/LightGBM, documentar versiones.\n",
    "\n",
    "---\n",
    "\n",
    "## Proyecto B — CLASIFICACIÓN  \n",
    "**Título:** Clasificación del tipo de mineral a partir de imágenes de difracción simulada (problema poco común)  \n",
    "**Dataset sugerido (Kaggle alternativo):** Siéntase libre de usar un dataset raro con clasificación multiclase. Una opción similar es el dataset de hojas ya propuesto anteriormente — sin embargo, para variar, proponemos usar un dataset de señales espectrales o morfometría (si no encuentra uno exacto en Kaggle, puede simular características).  \n",
    "> Nota: si el estudiante no encuentra exactamente el dataset de espectros en Kaggle, puede usar el siguiente dataset alternativo: Leaf Classification — https://www.kaggle.com/datasets/crawford/leaf-classification (aplicar las mismas instrucciones adaptadas).  \n",
    "\n",
    "> Para esta tarea el objetivo es trabajar con un **problema multiclase con alta dimensionalidad** y aplicar técnicas de reducción de dimensionalidad y calibración de probabilidad.\n",
    "\n",
    "### Contexto y motivación (para el estudiante)\n",
    "En aplicaciones industriales (minería, farmacéutica) y biológicas, la clasificación de materiales o especies puede basarse en descriptores complejos (espectros, morfometría, texturas). Estos problemas tienen muchas características (alto número de variables) y clases desbalanceadas. Aprender a preprocesar, reducir dimensionalidad y calibrar modelos probabilísticos es esencial.\n",
    "\n",
    "### Data definition (ejemplo general para dataset de características de señales o morfometría)\n",
    "- `id` — identificador único (int).  \n",
    "- `class` — etiqueta objetivo (string o int) con N clases (multiclase).  \n",
    "- `feat_1, feat_2, ..., feat_m` — descriptores numéricos (pueden ser coeficientes de forma, textura, bandas espectrales, etc.).  \n",
    "- Observaciones: muchas variables pueden ser correlacionadas o redundantes; puede existir desbalance entre clases.\n",
    "\n",
    "### Objetivo de la entrega\n",
    "Construir un clasificador multiclase robusto que maximice precisión balanceada y F1 macro, aplicar reducción de dimensionalidad para mejorar interpretabilidad y evaluar calibración de probabilidades.\n",
    "\n",
    "### Entregables específicos\n",
    "1. `notebook_clasificacion.ipynb` reproducible.  \n",
    "2. `REPORT.md` con análisis, resultados y discusión.  \n",
    "3. `requirements.txt`.\n",
    "\n",
    "### Tareas paso a paso (modo estudiante)\n",
    "\n",
    "#### 1. Exploración inicial (EDA)\n",
    "- Cargar datos y visualizar la distribución por clase (barras).  \n",
    "- Revisar características: resumen estadístico, correlaciones entre características.  \n",
    "- Detectar características con varianza cercana a cero (eliminar si aplica).\n",
    "\n",
    "#### 2. Preprocesamiento\n",
    "- Tratamiento de valores faltantes (imputación).  \n",
    "- Escalado de características (StandardScaler o RobustScaler si hay outliers).  \n",
    "- Opcional: aplicar técnicas de balanceo si hay clases muy desbalanceadas (SMOTE, undersampling), justificar elección.\n",
    "\n",
    "#### 3. Reducción de dimensionalidad y selección de características\n",
    "- Realizar PCA para entender varianza explicada y reducir dimensionalidad; mostrar gráfico de codo (explained variance).  \n",
    "- Alternativamente o complementariamente, realizar selección de características (SelectKBest, feature importance con Random Forest, L1-based selection).  \n",
    "- Documentar trade-offs: interpretabilidad vs. performance.\n",
    "\n",
    "#### 4. División de datos y estrategia de evaluación\n",
    "- Dividir en `train`/`test` (80/20) con `stratify` por la clase.  \n",
    "- Usar `StratifiedKFold` para validación durante búsqueda de hiperparámetros.  \n",
    "- Métricas principales: Accuracy, Precision/Recall por clase, F1-score macro, Balanced Accuracy. Usar matriz de confusión para análisis de errores.\n",
    "\n",
    "#### 5. Baseline y modelos a entrenar\n",
    "- Baseline simple: Logistic Regression multinomial o k-NN.  \n",
    "- Modelos recomendados a comparar (al menos 3):  \n",
    "  - Random Forest Classifier.  \n",
    "  - Gradient Boosting (XGBoost / LightGBM / CatBoost).  \n",
    "  - SVM con kernel (si dimensionalidad lo permite).  \n",
    "  - Neural Network simple (MLP) si hay suficientes muestras.  \n",
    "- Para cada modelo: búsqueda de hiperparámetros (Grid/Random CV) con `scoring='f1_macro'`.\n",
    "\n",
    "#### 6. Calibración de probabilidades\n",
    "- Evaluar si el modelo produce probabilidades bien calibradas (calibration curve, Brier score).  \n",
    "- Si es necesario, aplicar calibradores (`CalibratedClassifierCV`) y comparar resultados.\n",
    "\n",
    "#### 7. Interpretabilidad\n",
    "- Reportar importancias de características.  \n",
    "- Si se aplicó PCA, mostrar representación en 2D de componentes principales coloreada por clase (scatter) para visualizar separabilidad.  \n",
    "- Analizar errores: examinar casos donde el clasificador confunde clases cercanas.\n",
    "\n",
    "#### 8. Robustez y generalización\n",
    "- Evaluar performance por subgrupos (si los datos tienen metadatos: por origen, condición experimental, etc.).  \n",
    "- Prueba de sensibilidad a ruido: añadir ruido gaussiano a las características y medir degradación.\n",
    "\n",
    "#### 9. Conclusiones y recomendaciones\n",
    "- Mejor modelo y por qué.  \n",
    "- Recomendaciones para producción (umbral de decisión, si calibrar probabilidades, cómo tratar clase minoritaria).  \n",
    "- Limitaciones del estudio.\n",
    "\n",
    "### Criterio de evaluación sugerido\n",
    "- EDA y comprensión del problema: 20%  \n",
    "- Estrategia de preprocesamiento y justificación: 20%  \n",
    "- Modelado y tuning apropiado: 30%  \n",
    "- Evaluación, calibración e interpretabilidad: 20%  \n",
    "- Presentación, reproducibilidad y claridad: 10%\n",
    "\n",
    "### Tareas adicionales (bonus)\n",
    "- Implementar un pipeline de `scikit-learn` que integre preprocesamiento, reducción de dimensionalidad y modelo final.  \n",
    "- Crear una API mínima (Flask/FastAPI) que reciba un vector de características y devuelva la predicción con probabilidades.  \n",
    "- Implementar explicación local con LIME o SHAP para 3 instancias mal clasificadas y documentar interpretaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## Recomendaciones técnicas y formato de entrega\n",
    "- Usa Python 3.8+ y documenta versiones en `requirements.txt`.  \n",
    "- Incluye una celda de `Environment` al inicio del notebook indicando versiones principales (`pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `xgboost`/`lightgbm` si se usan).  \n",
    "- El `REPORT.md` debe incluir: resumen ejecutivo (máx 1 párrafo), metodología, resultados (tablas y figuras), conclusiones y pasos futuros.  \n",
    "- Opcional: anexar una carpeta `figures/` con los plots generados en alta resolución.\n",
    "\n",
    "---\n",
    "\n",
    "## Entregables finales (resumen)\n",
    "Para **cada proyecto** (A y B) debes subir al repositorio:\n",
    "- `notebook_regresion.ipynb` / `notebook_clasificacion.ipynb`  \n",
    "- `REPORT.md`  \n",
    "- `README.md` (con instrucciones para reproducir)  \n",
    "- `requirements.txt`  \n",
    "- Script o instrucciones para descargar datos (enlace a Kaggle y comando `kaggle` o instrucción manual)  \n",
    "\n",
    "---\n",
    "\n",
    "## Observación final\n",
    "- Explica y justifica cada decisión (por qué escalaste, por qué seleccionaste un modelo, por qué calibraste).  \n",
    "- La nota se asignará en función de la calidad del análisis, reproducibilidad, rigor en la evaluación y claridad del reporte.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
